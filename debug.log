#!/usr/bin/env python3
"""
server.py  â€“  local LLM chat interface
OpenAI-compatible streaming endpoint expected at
http://192.168.1.163:5000/v1/chat/completions
"""

import json, pathlib, uuid, time, asyncio, shlex, subprocess
from aiohttp import web, WSMsgType
import aiohttp_cors
import logging
import sys

# Configure logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('debug.log', mode='a')
    ]
)
logger = logging.getLogger(__name__)

# ---------- config -----------------------------------------------------------
ROOT_DIR       = pathlib.Path(__file__).parent
DATA_DIR       = ROOT_DIR / "data"
CHATS_FILE     = DATA_DIR / "chats.json"
SETTINGS_FILE  = DATA_DIR / "settings.json"
LLM_API_BASE   = "http://192.168.1.163:5000/v1/chat/completions"
DEFAULT_SET    = {"temp": 0.7, "max_tokens": 500, "top_p": 1.0, "dark": True}

DATA_DIR.mkdir(exist_ok=True)

# ---------- globals -----------------------------------------------------------
UserMessage = ""  # Will be replaced with actual user input
SystemInstruction = "You are Cortex, a helpful assistant that only answers concisely."
current_model = "koboldcpp"  # Default model name
api_request_count = 0  # Counter for model refresh (every 10 requests)
MODEL_API_URL = "http://192.168.1.163:5000/v1/models"

# ---------- helpers ----------------------------------------------------------
def sanitize(text: str) -> str:
    return text.replace("<", "&lt;").replace(">", "&gt;")

def load_json(path, default):
    return json.loads(path.read_text(encoding="utf-8")) if path.exists() else default

def save_json(path, obj):
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")

def ensure_files():
    if not CHATS_FILE.exists():
        save_json(CHATS_FILE, {})
    if not SETTINGS_FILE.exists():
        save_json(SETTINGS_FILE, DEFAULT_SET)

# ---------- storage ----------------------------------------------------------
def load_chats():
    return load_json(CHATS_FILE, {})

def save_chats(chats):
    save_json(CHATS_FILE, chats)

def load_settings():
    return load_json(SETTINGS_FILE, DEFAULT_SET.copy())

def save_settings(settings):
    save_json(SETTINGS_FILE, settings)

# ---------- HTTP streaming endpoint ------------------------------------------
async def chat_stream(request):
    """HTTP streaming endpoint for chat using curl requests"""
    logger.info(f"HTTP chat stream request from {request.remote}")
    try:
        data = await request.json()
        user_msg = sanitize(data["message"])
        history = data.get("history", [])
        settings = load_settings()
        temp = float(data.get("temperature", settings["temp"]))
        max_tokens = int(data.get("max_tokens", settings["max_tokens"]))
        top_p = float(data.get("top_p", settings["top_p"]))

        logger.info(f"HTTP stream request: message='{user_msg[:50]}...', history_length={len(history)}")
        logger.debug(f"Full request data: {json.dumps(data, indent=2)}")

        # Set up streaming response
        response = web.StreamResponse()
        response.headers['Content-Type'] = 'application/x-ndjson'
        response.headers['Cache-Control'] = 'no-cache'
        response.headers['Connection'] = 'keep-alive'
        await response.prepare(request)

        # Stream tokens using curl-based function
        token_count = 0
        async for token in stream_llm(user_msg, history, temp, max_tokens, top_p):
            token_count += 1
            if token_count <= 3:  # Log first few tokens
                logger.debug(f"Sending token {token_count}: {token}")

            # Send each token as a JSON line
            await response.write(json.dumps({"token": token}).encode() + b'\n')
            await response.drain()          # <-- FLUSH EACH TOKEN IMMEDIATELY

        # Send completion signal
        await response.write(json.dumps({"done": True}).encode() + b'\n')
        logger.info(f"HTTP stream completed successfully, sent {token_count} tokens")

        return response

    except Exception as e:
        logger.error(f"Error in HTTP chat stream: {e}", exc_info=True)
        return web.json_response({"error": str(e)}, status=500)

# ---------- model management -------------------------------------------------
async def get_current_model():
    """Get the current model from the API endpoint"""
    global current_model
    try:
        cmd = ["curl", "-s", MODEL_API_URL]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            data = json.loads(result.stdout)
            if data.get("data") and len(data["data"]) > 0:
                new_model = data["data"][0]["id"]
                if new_model != current_model:
                    logger.info(f"Model changed from {current_model} to {new_model}")
                    current_model = new_model
                else:
                    logger.debug(f"Model unchanged: {current_model}")
                return current_model
            else:
                logger.warning(f"No models found in API response, keeping current: {current_model}")
        else:
            logger.error(f"Failed to query models API: {result.stderr}")
    except Exception as e:
        logger.error(f"Error getting current model: {e}")

    return current_model

# ---------- LLM proxy via curl with 8-char chunks ---------------------------
async def stream_llm(prompt, history, temp, max_tokens, top_p):
    global api_request_count, current_model, UserMessage
    logger.info(f"stream_llm called with prompt: {prompt[:50]}..., history length: {len(history)}")
    logger.info(f"Settings: temp={temp}, max_tokens={max_tokens}, top_p={top_p}")

    # Check model every 10 requests
    api_request_count += 1
    if api_request_count % 10 == 0:
        logger.info(f"Refreshing model (request {api_request_count})")
        await get_current_model()

    logger.info(f"Using model: {current_model}")

    # Update UserMessage with the new prompt
    UserMessage = sanitize(prompt)
    logger.debug(f"UserMessage set to: {UserMessage}")

    # Build messages using variables
    msgs = [
        {"role": "system", "content": SystemInstruction},
        *history,
        {"role": "user", "content": UserMessage}
    ]

    payload = {
        "model": current_model,
        "messages": msgs,
        "temperature": temp,
        "max_tokens": max_tokens,
        "top_p": top_p,
        "stream": True
    }

    logger.debug(f"Full payload: {json.dumps(payload, indent=2)}")

    # Properly escape the JSON body for the shell
    json_str = shlex.quote(json.dumps(payload, separators=(',', ':')))

    cmd = [
        "curl", "-s", "-N",
        "-X", "POST",
        LLM_API_BASE,
        "-H", "Content-Type: application/json",
        "-d", json_str
    ]

    logger.info(f"Curl command: {' '.join(cmd[:8])}...")  # Don't log the full JSON

    try:
        proc = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        logger.info("Subprocess created successfully")

        buffer = ""  # Buffer to accumulate 8-character chunks

        async for line in proc.stdout:
            line = line.decode().strip()
            logger.debug(f"Raw line from curl: {line}")

            if line.startswith("data: "):
                chunk = line[6:]
                if chunk == "[DONE]":
                    logger.info("Received [DONE] signal")
                    # Send any remaining buffer
                    if buffer:
                        logger.debug(f"Sending final buffer: '{buffer}'")
                        yield buffer
                    break
                try:
                    delta = json.loads(chunk)["choices"][0]["delta"]
                    if "content" in delta:
                        content = delta["content"]
                        logger.debug(f"Received content: '{content}'")

                        # Add to buffer
                        buffer += content

                        # Send 8-character chunks
                        while len(buffer) >= 8:
                            chunk8 = buffer[:8]
                            logger.debug(f"Yielding 8-char chunk: '{chunk8}'")
                            yield chunk8
                            buffer = buffer[8:]

                except Exception as e:
                    logger.warning(f"Failed to parse chunk: {chunk}, error: {e}")
                    continue
            else:
                logger.debug(f"Non-data line: {line}")

        # Send any remaining content in buffer (less than 8 chars)
        if buffer:
            logger.debug(f"Sending remaining buffer: '{buffer}'")
            yield buffer

        # Check stderr for any errors
        stderr = await proc.stderr.read()
        if stderr:
            logger.error(f"Curl stderr: {stderr.decode()}")

        return_code = await proc.wait()
        logger.info(f"Subprocess completed with return code: {return_code}")

    except Exception as e:
        logger.error(f"Exception in stream_llm: {e}", exc_info=True)
        raise

# ---------- routes -----------------------------------------------------------
async def index(_):
    return web.FileResponse(ROOT_DIR / "public" / "index.html")

async def history_list(_):
    chats = load_chats()
    return web.json_response(list(chats.values()))

async def history_get(request):
    cid = request.match_info["id"]
    chats = load_chats()
    return web.json_response(chats[cid]) if cid in chats else web.json_response({"error": "not found"}, status=404)

async def history_delete(request):
    cid = request.match_info["id"]
    chats = load_chats()
    chats.pop(cid, None)
    save_chats(chats)
    return web.json_response({"ok": True})

async def history_rename(request):
    cid = request.match_info["id"]
    body = await request.json()
    new_name = sanitize(body["name"])
    chats = load_chats()
    if cid in chats:
        chats[cid]["name"] = new_name
        save_chats(chats)
    return web.json_response({"ok": True})

async def export_all(_):
    return web.json_response({"chats": load_chats(), "settings": load_settings()})

async def import_all(request):
    body = await request.json()
    if "chats" in body:
        save_chats(body["chats"])
    if "settings" in body:
        save_settings(body["settings"])
    return web.json_response({"ok": True})

async def get_settings(_):
    return web.json_response(load_settings())

async def post_settings(request):
    save_settings(await request.json())
    return web.json_response({"ok": True})

# ---------- websocket --------------------------------------------------------
async def websocket_handler(request):
    ws = web.WebSocketResponse()
    await ws.prepare(request)
    async for msg in ws:
        if msg.type == WSMsgType.TEXT:
            data = json.loads(msg.data)
            if data.get("action") == "stream":
                user_msg = sanitize(data["message"])
                history = data.get("history", [])
                settings = load_settings()
                temp = float(data.get("temperature", settings["temp"]))
                max_tokens = int(data.get("max_tokens", settings["max_tokens"]))
                top_p = float(data.get("top_p", settings["top_p"]))
                logger.info(f"WebSocket stream request: message='{user_msg[:50]}...', history_length={len(history)}")
                logger.debug(f"Full message data: {json.dumps(data, indent=2)}")
                try:
                    async for token in stream_llm(user_msg, history, temp, max_tokens, top_p):
                        await ws.send_str(json.dumps({"token": token}))
                    await ws.send_str(json.dumps({"done": True}))
                    logger.info("WebSocket stream completed successfully")
                except Exception as e:
                    logger.error(f"Error in WebSocket stream: {e}", exc_info=True)
                    await ws.send_str(json.dumps({"error": str(e)}))
        elif msg.type == WSMsgType.ERROR:
            logger.error(f"WebSocket error: {ws.exception()}")
    return ws

# ---------- app --------------------------------------------------------------
def build_app():
    app = web.Application()
    cors = aiohttp_cors.setup(app, defaults={"*": aiohttp_cors.ResourceOptions(
        allow_credentials=True, expose_headers="*", allow_headers="*", allow_methods="*")})
    app.router.add_get("/", index)
    app.router.add_get("/api/history", history_list)
    app.router.add_get("/api/history/{id}", history_get)
    app.router.add_delete("/api/history/{id}", history_delete)
    app.router.add_patch("/api/history/{id}", history_rename)
    app.router.add_get("/api/export", export_all)
    app.router.add_post("/api/import", import_all)
    app.router.add_get("/api/settings", get_settings)
    app.router.add_post("/api/settings", post_settings)
    app.router.add_post("/api/chat", chat_stream)
    app.router.add_get("/api/stream", websocket_handler)
    app.router.add_static("/", path=ROOT_DIR / "public", name="static")
    for r in list(app.router.routes()):
        cors.add(r)
    return app

if __name__ == "__main__":
    ensure_files()
    logger.info("Starting server on 192.168.1.163:8282")
    web.run_app(build_app(), host="192.168.1.163", port=8282)2025-09-13 20:33:10,588 - __main__ - INFO - Starting server on 192.168.1.163:8282
2025-09-13 20:33:10,589 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-13 20:33:13,787 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:33:13 -0600] "GET / HTTP/1.1" 304 179 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:33:13,799 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:33:13 -0600] "GET /styles.css HTTP/1.1" 304 180 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:33:13,801 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:33:13 -0600] "GET /marked.min.js HTTP/1.1" 304 179 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:33:13,801 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:33:13 -0600] "GET /highlight-dark.css HTTP/1.1" 304 178 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:33:13,802 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:33:13 -0600] "GET /highlight.min.js HTTP/1.1" 304 179 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:33:13,820 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:33:13 -0600] "GET /script.js HTTP/1.1" 200 245 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:33:13,866 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:33:13 -0600] "GET /favicon.ico HTTP/1.1" 404 173 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:33:17,087 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:33:17 -0600] "GET / HTTP/1.1" 304 179 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:33:17,097 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:33:17 -0600] "GET /script.js HTTP/1.1" 304 180 "http://192.168.1.163:8282/?" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:40:20,116 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:40:20 -0600] "GET /script.js HTTP/1.1" 304 180 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:59:45,007 - __main__ - INFO - Starting server on 192.168.1.163:8282
2025-09-13 20:59:45,008 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-13 20:59:50,141 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:59:50 -0600] "GET / HTTP/1.1" 304 179 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:59:50,151 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:59:50 -0600] "GET /styles.css HTTP/1.1" 304 180 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:59:50,152 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:59:50 -0600] "GET /marked.min.js HTTP/1.1" 304 179 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:59:50,152 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:59:50 -0600] "GET /highlight-dark.css HTTP/1.1" 304 178 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:59:50,153 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:59:50 -0600] "GET /script.js HTTP/1.1" 304 180 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 20:59:55,285 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:19:59:55 -0600] "GET / HTTP/1.1" 304 179 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 21:02:00,832 - __main__ - INFO - Starting server on 192.168.1.163:8282
2025-09-13 21:02:00,833 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-13 21:08:35,802 - __main__ - INFO - === SERVER STARTUP DIAGNOSTIC ===
2025-09-13 21:08:35,802 - __main__ - INFO - ROOT_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE
2025-09-13 21:08:35,802 - __main__ - INFO - DATA_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE\data
2025-09-13 21:08:35,802 - __main__ - INFO - CHATS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\chats.json
2025-09-13 21:08:35,802 - __main__ - INFO - SETTINGS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\settings.json
2025-09-13 21:08:35,802 - __main__ - INFO - debug.log path: c:\Users\sirbo\Desktop\AI-INTERFACE\debug.log
2025-09-13 21:08:35,802 - __main__ - INFO - === END DIAGNOSTIC ===
2025-09-13 21:08:35,802 - __main__ - INFO - Starting server on 192.168.1.163:8282
2025-09-13 21:08:35,803 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-13 21:08:48,077 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:20:08:48 -0600] "GET /script.js HTTP/1.1" 304 180 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-13 21:08:48,078 - aiohttp.access - INFO - 192.168.1.163 [13/Sep/2025:20:08:48 -0600] "GET /highlight.min.js HTTP/1.1" 304 179 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 08:12:58,114 - __main__ - INFO - === SERVER STARTUP DIAGNOSTIC ===
2025-09-14 08:12:58,115 - __main__ - INFO - ROOT_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE
2025-09-14 08:12:58,115 - __main__ - INFO - DATA_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE\data
2025-09-14 08:12:58,115 - __main__ - INFO - CHATS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\chats.json
2025-09-14 08:12:58,115 - __main__ - INFO - SETTINGS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\settings.json
2025-09-14 08:12:58,115 - __main__ - INFO - debug.log path: c:\Users\sirbo\Desktop\AI-INTERFACE\debug.log
2025-09-14 08:12:58,115 - __main__ - INFO - === END DIAGNOSTIC ===
2025-09-14 08:12:58,116 - __main__ - INFO - Starting server on 192.168.1.163:8282
2025-09-14 08:12:58,117 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-14 08:13:03,139 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:07:13:03 -0600] "GET / HTTP/1.1" 304 179 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 08:13:03,152 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:07:13:03 -0600] "GET /styles.css HTTP/1.1" 304 180 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 08:13:03,152 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:07:13:03 -0600] "GET /highlight-dark.css HTTP/1.1" 304 178 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 08:13:03,153 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:07:13:03 -0600] "GET /marked.min.js HTTP/1.1" 304 179 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 08:13:03,153 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:07:13:03 -0600] "GET /highlight.min.js HTTP/1.1" 304 179 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 08:13:03,153 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:07:13:03 -0600] "GET /script.js HTTP/1.1" 304 180 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 08:13:03,220 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:07:13:03 -0600] "GET /favicon.ico HTTP/1.1" 404 173 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 08:14:13,858 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:07:14:13 -0600] "GET / HTTP/1.1" 304 179 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 08:15:02,156 - __main__ - INFO - HTTP chat stream request from 192.168.1.163
2025-09-14 08:15:02,158 - __main__ - INFO - HTTP stream request: message='test...', history_length=0
2025-09-14 08:15:02,158 - __main__ - DEBUG - Full request data: {
  "message": "test",
  "history": []
}
2025-09-14 08:15:02,158 - __main__ - INFO - stream_llm_json called with prompt: test..., history length: 0
2025-09-14 08:15:02,158 - __main__ - INFO - Settings: temp=0.7, max_tokens=500, top_p=1.0
2025-09-14 08:15:02,158 - __main__ - INFO - Using model: koboldcpp
2025-09-14 08:15:02,158 - __main__ - DEBUG - Request payload: {
  "model": "koboldcpp",
  "messages": [
    {
      "role": "system",
      "content": "You are Cortex, a helpful assistant that only answers concisely."
    },
    {
      "role": "user",
      "content": "test"
    }
  ],
  "max_tokens": 500,
  "temperature": 0.7
}
2025-09-14 08:15:02,158 - __main__ - INFO - execute_streaming_json_curl_request called to http://192.168.1.163:5000/v1/chat/completions
2025-09-14 08:15:02,158 - __main__ - DEBUG - Executing streaming curl command: curl -X POST -s -N http://192.168.1.163:5000/v1/chat/completions -H 'Content-Type: application/json' -d -d '{"model": "koboldcpp", "messages": [{"role": "system", "content": "You are Cortex, a helpful assista...'
2025-09-14 08:15:03,703 - __main__ - INFO - stream_llm_json completed, yielded 0 tokens
2025-09-14 08:15:03,703 - __main__ - INFO - HTTP stream completed successfully, sent 0 tokens
2025-09-14 08:15:03,703 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:07:15:02 -0600] "POST /api/chat HTTP/1.1" 200 231 "-" "curl/8.12.1"
2025-09-14 08:31:42,946 - __main__ - INFO - === SERVER STARTUP DIAGNOSTIC ===
2025-09-14 08:31:42,946 - __main__ - INFO - ROOT_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE
2025-09-14 08:31:42,946 - __main__ - INFO - DATA_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE\data
2025-09-14 08:31:42,946 - __main__ - INFO - CHATS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\chats.json
2025-09-14 08:31:42,946 - __main__ - INFO - SETTINGS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\settings.json
2025-09-14 08:31:42,946 - __main__ - INFO - debug.log path: c:\Users\sirbo\Desktop\AI-INTERFACE\debug.log
2025-09-14 08:31:42,947 - __main__ - INFO - === END DIAGNOSTIC ===
2025-09-14 08:31:42,947 - __main__ - INFO - Starting server on 192.168.1.163:8282
2025-09-14 08:31:42,948 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-14 08:31:46,632 - __main__ - INFO - === SERVER STARTUP DIAGNOSTIC ===
2025-09-14 08:31:46,632 - __main__ - INFO - ROOT_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE
2025-09-14 08:31:46,633 - __main__ - INFO - DATA_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE\data
2025-09-14 08:31:46,633 - __main__ - INFO - CHATS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\chats.json
2025-09-14 08:31:46,633 - __main__ - INFO - SETTINGS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\settings.json
2025-09-14 08:31:46,633 - __main__ - INFO - debug.log path: c:\Users\sirbo\Desktop\AI-INTERFACE\debug.log
2025-09-14 08:31:46,633 - __main__ - INFO - === END DIAGNOSTIC ===
2025-09-14 08:31:46,633 - __main__ - INFO - Starting server on 192.168.1.163:8282
2025-09-14 08:31:46,634 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-14 08:34:21,375 - __main__ - INFO - === SERVER STARTUP DIAGNOSTIC ===
2025-09-14 08:34:21,375 - __main__ - INFO - ROOT_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE
2025-09-14 08:34:21,375 - __main__ - INFO - DATA_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE\data
2025-09-14 08:34:21,375 - __main__ - INFO - CHATS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\chats.json
2025-09-14 08:34:21,376 - __main__ - INFO - SETTINGS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\settings.json
2025-09-14 08:34:21,376 - __main__ - INFO - debug.log path: c:\Users\sirbo\Desktop\AI-INTERFACE\debug.log
2025-09-14 08:34:21,376 - __main__ - INFO - === END DIAGNOSTIC ===
2025-09-14 08:34:21,376 - __main__ - INFO - Starting server on 192.168.1.163:8282
2025-09-14 08:34:21,377 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-14 08:37:31,031 - __main__ - INFO - === SERVER STARTUP DIAGNOSTIC ===
2025-09-14 08:37:31,031 - __main__ - INFO - ROOT_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE
2025-09-14 08:37:31,031 - __main__ - INFO - DATA_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE\data
2025-09-14 08:37:31,031 - __main__ - INFO - CHATS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\chats.json
2025-09-14 08:37:31,032 - __main__ - INFO - SETTINGS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\settings.json
2025-09-14 08:37:31,032 - __main__ - INFO - debug.log path: c:\Users\sirbo\Desktop\AI-INTERFACE\debug.log
2025-09-14 08:37:31,032 - __main__ - INFO - === END DIAGNOSTIC ===
2025-09-14 08:37:31,032 - __main__ - INFO - Starting server on 192.168.1.163:8282
2025-09-14 08:37:31,033 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-14 08:45:46,851 - __main__ - INFO - === SERVER STARTUP DIAGNOSTIC ===
2025-09-14 08:45:46,851 - __main__ - INFO - ROOT_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE
2025-09-14 08:45:46,851 - __main__ - INFO - DATA_DIR: c:\Users\sirbo\Desktop\AI-INTERFACE\data
2025-09-14 08:45:46,851 - __main__ - INFO - CHATS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\chats.json
2025-09-14 08:45:46,851 - __main__ - INFO - SETTINGS_FILE: c:\Users\sirbo\Desktop\AI-INTERFACE\data\settings.json
2025-09-14 08:45:46,851 - __main__ - INFO - debug.log path: c:\Users\sirbo\Desktop\AI-INTERFACE\debug.log
2025-09-14 08:45:46,851 - __main__ - INFO - === END DIAGNOSTIC ===
2025-09-14 08:45:46,852 - __main__ - INFO - Starting server on 192.168.1.163:8282
2025-09-14 08:45:46,852 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-14 08:58:55,980 - __main__ - INFO - Starting server on http://192.168.1.163:8282
2025-09-14 08:58:55,981 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-14 08:58:55,982 - __main__ - INFO - AIOHTTP ClientSession created.
2025-09-14 08:58:55,982 - __main__ - INFO - Querying models from http://192.168.1.163:5000/v1/models
2025-09-14 08:58:55,983 - __main__ - INFO - Model updated: koboldcpp -> koboldcpp/gemma3-27b-abliterated-dpo.i1-IQ2_M
2025-09-14 09:03:38,571 - __main__ - INFO - AIOHTTP ClientSession closed.
2025-09-14 09:03:41,865 - __main__ - INFO - Starting server on http://192.168.1.163:8282
2025-09-14 09:03:41,865 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-14 09:03:41,866 - __main__ - INFO - AIOHTTP ClientSession created.
2025-09-14 09:03:41,866 - __main__ - INFO - Querying models from http://192.168.1.163:5000/v1/models
2025-09-14 09:03:41,867 - __main__ - INFO - Model updated: koboldcpp -> koboldcpp/gemma3-27b-abliterated-dpo.i1-IQ2_M
2025-09-14 09:24:06,499 - __main__ - INFO - Starting server on http://192.168.1.163:8282
2025-09-14 09:24:06,500 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-14 09:24:06,501 - __main__ - INFO - Updating model via curl: curl -s -N -X GET -H 'Accept: application/json' http://192.168.1.163:5000/v1/models
2025-09-14 09:24:06,537 - __main__ - INFO - Model changed: koboldcpp -> koboldcpp/gemma3-27b-abliterated-dpo.i1-IQ2_M
2025-09-14 09:24:10,526 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:08:24:10 -0600] "GET /script.js HTTP/1.1" 304 180 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 09:24:10,587 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:08:24:10 -0600] "GET /favicon.ico HTTP/1.1" 404 173 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 16:30:47,054 - __main__ - INFO - Starting server on http://192.168.1.163:8282
2025-09-14 16:30:47,055 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-14 16:30:50,576 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:15:30:50 -0600] "GET / HTTP/1.1" 304 179 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 16:30:50,650 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:15:30:50 -0600] "GET /styles.css HTTP/1.1" 304 180 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 16:30:50,650 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:15:30:50 -0600] "GET /marked.min.js HTTP/1.1" 304 179 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 16:30:50,651 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:15:30:50 -0600] "GET /highlight.min.js HTTP/1.1" 304 179 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 16:30:50,652 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:15:30:50 -0600] "GET /highlight-dark.css HTTP/1.1" 304 178 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 16:30:50,652 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:15:30:50 -0600] "GET /script.js HTTP/1.1" 304 180 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 16:30:50,705 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:15:30:50 -0600] "GET /favicon.ico HTTP/1.1" 404 173 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 16:31:41,182 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:15:31:41 -0600] "GET / HTTP/1.1" 304 179 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 16:47:14,019 - aiohttp.access - INFO - 192.168.1.163 [14/Sep/2025:15:47:14 -0600] "GET /favicon.ico HTTP/1.1" 404 173 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-14 16:59:23,445 - __main__ - INFO - Starting server on http://192.168.1.163:8282
2025-09-14 17:00:27,984 - __main__ - INFO - Starting server on http://192.168.1.163:8282
2025-09-14 17:00:27,984 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-14 17:12:56,373 - __main__ - INFO - Starting server on http://192.168.1.163:8282
2025-09-14 17:12:56,374 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-14 17:15:33,767 - __main__ - INFO - Starting server on http://192.168.1.163:8282
2025-09-14 17:15:33,768 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-14 17:15:33,769 - __main__ - INFO - === Server starting up ===
2025-09-14 17:15:33,769 - __main__ - INFO - AppState initialized with client_session: <aiohttp.client.ClientSession object at 0x00000180C5985010>
2025-09-17 10:30:29,697 - __main__ - INFO - Starting server on http://192.168.1.163:8282
2025-09-17 10:30:29,698 - asyncio - DEBUG - Using proactor: IocpProactor
2025-09-17 10:30:36,102 - aiohttp.access - INFO - 192.168.1.163 [17/Sep/2025:09:30:36 -0600] "GET / HTTP/1.1" 200 238 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-17 10:30:36,113 - aiohttp.access - INFO - 192.168.1.163 [17/Sep/2025:09:30:36 -0600] "GET /styles.css HTTP/1.1" 200 238 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-17 10:30:36,114 - aiohttp.access - INFO - 192.168.1.163 [17/Sep/2025:09:30:36 -0600] "GET /highlight-dark.css HTTP/1.1" 200 235 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-17 10:30:36,114 - aiohttp.access - INFO - 192.168.1.163 [17/Sep/2025:09:30:36 -0600] "GET /highlight.min.js HTTP/1.1" 200 243 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-17 10:30:36,126 - aiohttp.access - INFO - 192.168.1.163 [17/Sep/2025:09:30:36 -0600] "GET /marked.min.js HTTP/1.1" 200 243 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-17 10:30:36,134 - aiohttp.access - INFO - 192.168.1.163 [17/Sep/2025:09:30:36 -0600] "GET /script.js HTTP/1.1" 200 244 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-17 10:30:36,178 - aiohttp.access - INFO - 192.168.1.163 [17/Sep/2025:09:30:36 -0600] "GET /favicon.ico HTTP/1.1" 404 173 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-17 10:31:44,588 - aiohttp.access - INFO - 192.168.1.163 [17/Sep/2025:09:31:44 -0600] "GET / HTTP/1.1" 200 238 "http://192.168.1.163:8282/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
2025-09-17 10:31:44,600 - aiohttp.access - INFO - 192.168.1.163 [17/Sep/2025:09:31:44 -0600] "GET /script.js HTTP/1.1" 304 179 "http://192.168.1.163:8282/?" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36"
